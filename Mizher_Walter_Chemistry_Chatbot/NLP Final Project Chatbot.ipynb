{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chemical Element Reference Chatbot\n",
    "# Melek Mizher - November 2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import wikipedia\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import regex as re\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#!pip install beautifulsoup4\n",
    "#!pip install wikipedia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Suppress warning messages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Extraction from Wikipedia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#List of all the Elements in the Periodic table by Atomic Number\n",
    "\n",
    "Elements = \"Hydrogen,Helium,Lithium,Beryllium,Boron,Carbon,Nitrogen,Oxygen,Fluorine,Neon,Sodium,Magnesium,Aluminum,Silicon,Phosphorus,Sulfur,Chlorine,Argon,Potassium,Calcium,Scandium,Titanium,Vanadium,Chromium,Manganese,Iron,Cobalt,Nickel,Copper,Zinc,Gallium,Germanium,Arsenic,Selenium,Bromine,Krypton,Rubidium,Strontium,Yttrium,Zirconium,Niobium,Molybdenum,Technetium,Ruthenium,Rhodium,Palladium,Silver,Cadmium,Indium,Tin,Antimony,Tellurium,Iodine,Xenon,Cesium,Barium,Lanthanum,Cerium,Praseodymium,Neodymium,Promethium,Samarium,Europium,Gadolinium,Terbium,Dysprosium,Holmium,Erbium,Thulium,Ytterbium,Lutetium,Hafnium,Tantalum,Tungsten,Rhenium,Osmium,Iridium,Platinum,Gold,Mercury,Thallium,Lead,Bismuth,Polonium,Astatine,Radon,Francium,Radium,Actinium,Thorium,Protactinium,Uranium,Neptunium,Plutonium,Americium,Curium,Berkelium,Californium,Einsteinium,Fermium,Mendelevium,Nobelium,Lawrencium,Rutherfordium,Dubnium,Seaborgium,Bohrium,Hassium,Meitnerium,Darmstadtium,Roentgenium,Copernicium,Nihonium,Flevorium,Moscovium,Livermorium,Tennessine,Oganesson\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Elements_Symbols = \"H,He,Li,Be,B,C,N,O,F,Ne,Na,Mg,Al,Si,P,S,Cl,Ar,K,Ca,Sc,Ti,V,Cr,Mn,Fe,Co,Ni,Cu,Zn,Ga,Ge,As,Se,Br,Kr,Rb,Sr,Y,Zr,Nb,Mo,Tc,Ru,Rh,Pd,Ag,Cd,In,Sn,Sb,Te,I,Xe,Cs,Ba,La,Ce,Pr,Nd,Pm,Sm,Eu,Gd,Tb,Dy,Ho,Er,Tm,Yb,Lu,Hf,Ta,W,Re,Os,Ir,Pt,Au,Hg,Tl,Pb,Bi,Po,At,Rn,Fr,Ra,Ac,Th,Pa,U,Np,Pu,Am,Cm,Bk,Cf,Es,Fm,Md,No,Lr,Rf,Db,Sg,Bh,Hs,Mt,Ds,Rg,Cn,Nh,Fl,Mc,Lv,Ts,Og\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Turns all the names to a List\n",
    "Elements = Elements.split(sep=',')\n",
    "Elements_Symbols = Elements_Symbols.split(sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Chemical Element Dataset by extracting Wikipedia Articles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for Element in Elements:\n",
    "    if Element == \"Mercury\":    # Prevents disambiguation problem for Mercury\n",
    "        Element = Element + \"_(element)\"\n",
    "    new_doc = wikipedia.page(Element, auto_suggest=False).content    #This extracts Element wikipedia page\n",
    "    if Element == \"Mercury_(element)\": # Returns variable to correct name\n",
    "        Element = \"Mercury\"\n",
    "    new_doc = new_doc.split(sep='\\n\\n\\n== References') # Separates final part of the Article\n",
    "    globals()[Element] = new_doc[0]\n",
    "    new_doc = globals()[Element].split(sep='\\n\\n\\n== See also')   # (Notes,See Also,References,etc.)\n",
    "    globals()[Element] = new_doc[0]\n",
    "    new_doc = globals()[Element].split(sep='\\n\\n\\n== Notes')      # This is repeated to ensure that sections are removed\n",
    "    globals()[Element] = new_doc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate List from Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Data = [globals()[Element] for Element in Elements]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_corpus_df = pd.DataFrame({'Element':Elements, 'Symbol':Elements_Symbols, 'Data':Data})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_corpus_df[\"Atomic Number\"] = raw_corpus_df.index+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset has been created with Element name, symbol, wikipedia article text, and atomic number"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_corpus_df.to_csv(\"Chemical_Element_Data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset is now saved as a CSV file for fast loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Dataset from CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv(\"Chemical_Element_Data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub('[^a-zA-Z]', ' ', str(text))\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_tags(text):\n",
    "    return re.sub(\"&lt;/?.*?&gt;\", \" &lt;&gt; \", text)\n",
    "\n",
    "def remove_special_chars_and_digits(text):\n",
    "    return re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "\n",
    "def tokenize(document, tokenize=\"word\"):\n",
    "    if tokenize == \"word\":\n",
    "        tokens = nltk.word_tokenize(document)\n",
    "    else:\n",
    "        tokens = nltk.sent_tokenize(document)\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def WalterProcess(document):\n",
    "\n",
    "    document = remove_punctuation(document)\n",
    "    document = lower_case(document)\n",
    "    document = remove_tags(document)\n",
    "    document = remove_special_chars_and_digits(document)\n",
    "    #document = tokenize(document, tokenize)\n",
    "\n",
    "    return document"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m final_corpus \u001B[38;5;241m=\u001B[39m corpus_df\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m      2\u001B[0m final_corpus[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m corpus_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(WalterProcess)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'corpus_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_corpus = corpus_df.copy()\n",
    "final_corpus['Data'] = corpus_df['Data'].apply(WalterProcess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m final_corpus\n",
      "\u001B[0;31mNameError\u001B[0m: name 'final_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "final_corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m final_corpus\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal_Chemical_Element_Data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'final_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "final_corpus.to_csv(\"Final_Chemical_Element_Data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging Section"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#Ignore this Section"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Walter Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def Walter(model, question, context_index):\n",
    "\n",
    "    # Selects Appropriate Chemical Element Dataset\n",
    "    context = final_corpus.Data[context_index]\n",
    "\n",
    "    # Model Selection\n",
    "    if model == 1:\n",
    "        model = pipeline(model='distilbert-base-cased-distilled-squad', revision='626af31')\n",
    "    if model == 2:\n",
    "        model = pipeline(model='deepset/roberta-base-squad2')\n",
    "    if model == 3:\n",
    "        model = pipeline(model='deepset/tinyroberta-squad2')\n",
    "    if model == 4:\n",
    "        model = pipeline(model='deepset/minilm-uncased-squad2')\n",
    "    if model == 5:\n",
    "        model = pipeline(model='mrm8488/longformer-base-4096-finetuned-squadv2')\n",
    "    # Process Question\n",
    "    question = WalterProcess(question)\n",
    "\n",
    "    # Generate Response\n",
    "    response = model(question=question, context=context)\n",
    "    #print(\"Score:\", response['score'])\n",
    "\n",
    "    return response['answer']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/6.91k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60eb44fd18024dee8486722c2d6515dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutrons\n"
     ]
    }
   ],
   "source": [
    "model=2\n",
    "question = \"Why can lithium explode?\"\n",
    "current_index = 2\n",
    "\n",
    "response = Walter(model, question, current_index)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/3.64k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "245c10ee1e0447f2a273018b81395eed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "anionic complexes\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/6.91k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "078051d5f694485b8b6b5e3de823227b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "chemical\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/3.52k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0de993d0ceea42ae80ec5824f44812d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cell contains free iron\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/3.48k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdfb7829276742cabba2a3a29f0670df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "iron is the most abundant element on earth\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/3.50k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6575397c26f54426a2e2a66c65a57ce7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "free iron\n"
     ]
    }
   ],
   "source": [
    "# Manual Generation for Quick DataFrame Generation\n",
    "\n",
    "model=5\n",
    "question = \"What type of element is Iron?\"\n",
    "current_index = 25\n",
    "\n",
    "for model in range(1,6):\n",
    "    response = Walter(model, question, current_index)\n",
    "    print(model)\n",
    "    print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Chatbot Program with Basic Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Introduction\n",
    "    print(\"Walter:  Hello, my name is Walter. I know information about all the known Chemical Elements.\")\n",
    "    print(\"Walter:  What should I call you?\\n\")\n",
    "    username = input()\n",
    "    if username.lower() in ['quit', 'cancel', 'exit', 'escape']:\n",
    "        print(f\"Walter:  Good bye!\")\n",
    "        sys.exit()\n",
    "\n",
    "    model = random.randrange(1,6) # Random Model Selection from 1 to 5\n",
    "\n",
    "    print(f\"{username}:  {username}.\\n\")\n",
    "    print(f\"Walter:  Perfect, {username}. I would like to tell you that I am allergic to punctuation.\")\n",
    "\n",
    "    # Begin Loop\n",
    "    while True:\n",
    "\n",
    "        # Initialize Chatbot Loop\n",
    "        understand = False\n",
    "        print(\"Walter:  What Element can I help you learn more about?\\n\")\n",
    "        user_response = input()\n",
    "        current_index = 0\n",
    "        print(f\"{username}:  {user_response}\\n\")\n",
    "        user_response = user_response.lower()\n",
    "        if user_response in ['quit', 'cancel', 'exit', 'escape']:\n",
    "            print(f\"Walter:  Good bye {username}!\")\n",
    "            break\n",
    "\n",
    "        current_element = user_response.capitalize()\n",
    "\n",
    "        # Confirm Index of Element of Interest\n",
    "        if current_element in final_corpus['Element'].values:\n",
    "            current_index = final_corpus[final_corpus['Element']==current_element].index[0]\n",
    "            understand = True\n",
    "\n",
    "        # Confirm Index of Symbol of Interest and return Element name\n",
    "        elif current_element in final_corpus['Symbol'].values:\n",
    "            current_index = final_corpus[final_corpus['Symbol']==current_element].index[0]\n",
    "            current_element = final_corpus['Element'][current_index]\n",
    "            understand = True\n",
    "\n",
    "        # Misunderstand user query.\n",
    "        else:\n",
    "            understand = False\n",
    "\n",
    "        # Confirm Interest in given Element.\n",
    "        if understand == True:\n",
    "            print(f\"Walter:  {username}, I see that you want to learn more about {current_element}, is that correct?\\n\")\n",
    "            user_response = input()\n",
    "            print(f\"{username}:  {user_response}\\n\")\n",
    "            user_response = user_response.lower()\n",
    "\n",
    "            # Proceeed with Operation\n",
    "            if user_response in ['yes', 'y', 'yep', 'correct', 'got it']:\n",
    "                print(f\"Walter:  Got it, {username}!, What would you like to learn about {current_element}?\\n\")\n",
    "                user_query = input()\n",
    "                print(f\"{username}:  {user_query}\\n\")\n",
    "                user_query = user_query.lower()\n",
    "\n",
    "                # Give summary if user simply wants a Summary\n",
    "                if 'summary' in user_query:\n",
    "                    if current_element == \"Mercury\":\n",
    "                        temp = \"Mercury_(element)\"\n",
    "                    else:\n",
    "                        temp = current_element\n",
    "                    summary = wikipedia.summary(temp, sentences=4, auto_suggest=False)\n",
    "                    print(f\"Walter:  {summary}\\n\")\n",
    "\n",
    "                else:\n",
    "                    #This is where the magic happens\n",
    "                    model = 1\n",
    "                    print(f\"Walter:  Give me a few seconds to think about it.\\n\")\n",
    "                    response = Walter(model, user_query, current_index)\n",
    "                    print(f\"Walter:  {response}\\n\")\n",
    "\n",
    "\n",
    "                # Check if user wants to ask another question.\n",
    "                print(f\"Walter:  Do you have any other questions?\\n\")\n",
    "                user_response = input()\n",
    "                print(f\"{username}: {user_response}\\n\")\n",
    "                user_response = user_response.lower()\n",
    "                if user_response in ['yes', 'y', 'yep', 'correct', 'got it']:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Walter:  Good bye {username}! It was a pleasure to help you.\")\n",
    "                    break\n",
    "\n",
    "            # Misunderstanding: Abort Operation\n",
    "            else:\n",
    "                print(f\"Walter:  I'm sorry {username}. I must have misunderstood you. Let's try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Walter:  Sorry {username}, I didn't quite understand you. Let's try again.\")\n",
    "            continue\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Word Analysis Leveraging Tendency of Elements Restricted Reasoning WALPTERR or WALTER for short."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#response = requests.get(url=\"https://en.wikipedia.org/wiki/Hydrogen\")\n",
    "#print(response.status_code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(response.text, 'html.parser')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences\n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
    "\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Generating response\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response\n",
    "\n",
    "\n",
    "flag=True\n",
    "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                print(\"ROBO: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}